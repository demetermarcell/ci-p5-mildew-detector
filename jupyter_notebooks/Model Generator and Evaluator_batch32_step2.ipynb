{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "813fcb18",
   "metadata": {},
   "source": [
    "# Modelling and Evaluation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21238f09",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Rebuild data generators with batch size = 32 (same augmentation as Step 1 for training; rescale only for validation/test).\n",
    "* Load the top 5 scenarios from Step 1 and prepare them for retraining.\n",
    "* Create the CNN model for each selected scenario.\n",
    "* Fit each model (EarlyStopping + best‐model checkpoint).\n",
    "* Evaluate each run on the validation set and collect: loss, accuracy, precision, recall, F1, and a confusion matrix.\n",
    "* Build a simple leaderboard to compare runs and pick the top candidates for the next step.\n",
    "  \n",
    "\n",
    "## Inputs\n",
    "\n",
    "* inputs/mildew-dataset/cherry-leaves/train\n",
    "* inputs/mildew-dataset/cherry-leaves/test\n",
    "* inputs/mildew-dataset/cherry-leaves/validation\n",
    "* image shape embeddings\n",
    "* Step-1 leaderboard (outputs/step_1/reports/grid_report_bs16.csv) to select the top 5 configurations\n",
    "\n",
    "## Outputs\n",
    "* Best-epoch model files per scenario.\n",
    "* Training histories.\n",
    "* Learning-curve plots (accuracy/loss).\n",
    "* Validation metrics per run. (loss, accuracy, precision, recall, F1, confusion matrix)\n",
    "* Consolidated leaderboard for Step 2. (sorted by validation accuracy, tie-break by validation loss)\n",
    "* Shortlist (top 3) ready for test-set evaluation in the final step\n",
    "\n",
    "## Additional Comments | Insights | Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f9af52",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83795410",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e23eb02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, math, json, itertools, time, joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread\n",
    "from pathlib import Path\n",
    "\n",
    "# TensorFlow and Keras:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Sklearn:\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57a0a1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84af3a75",
   "metadata": {},
   "source": [
    "## Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "076422ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 27\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4da49b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a6c1d9",
   "metadata": {},
   "source": [
    "## Define Main Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a961578",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'step_2'\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Set number of epochs\n",
    "epochs = 25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eed715",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58054516",
   "metadata": {},
   "source": [
    "### Create Run Tag Hashes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "946792f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tag(cfg: dict, version: str, batch_size: int, seed: int | None = None, include_seed: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Build a readable tag like:\n",
    "      step_1_bs16_k3_do0.5_act-relu_opt-adam_seed27\n",
    "    \"\"\"\n",
    "    parts = [\n",
    "        version,\n",
    "        f\"bs{batch_size}\",\n",
    "        f\"k{cfg['kernel_size']}\",\n",
    "        f\"do{cfg['dropout']}\",\n",
    "        f\"act-{cfg['activation']}\",\n",
    "        f\"opt-{cfg['optimizer']}\",\n",
    "    ]\n",
    "    if include_seed and seed is not None:\n",
    "        parts.append(f\"seed{seed}\")\n",
    "    return \"_\".join(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4befe7c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8bcded",
   "metadata": {},
   "source": [
    "# Set Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34aff81",
   "metadata": {},
   "source": [
    "  ## Set Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b49532c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New working directory: /Users/marcelldemeter/GIT/CodeInstitute/ci-p5-mildew-detector \n"
     ]
    }
   ],
   "source": [
    "# Parent directory\n",
    "parent_dir =  \"/Users/marcelldemeter/GIT/CodeInstitute/ci-p5-mildew-detector\"\n",
    "\n",
    "# Change working directory to parent directory\n",
    "os.chdir(parent_dir)\n",
    "print (f\"New working directory: {os.getcwd()} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac8bcbe",
   "metadata": {},
   "source": [
    "## Set Input Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16455d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"inputs/mildew-dataset/cherry-leaves\"\n",
    "train_dir = os.path.join(parent_dir, dataset_dir, \"train\")\n",
    "validation_dir = os.path.join(parent_dir, dataset_dir, \"validation\")\n",
    "test_dir = os.path.join(parent_dir, dataset_dir, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3077699",
   "metadata": {},
   "source": [
    "## Set Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6424fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old version is already available create a new version.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = f'outputs/{version}'\n",
    "\n",
    "# Create main output directory if it doesn’t exist\n",
    "if 'outputs' in os.listdir(parent_dir) and version in os.listdir(parent_dir + '/outputs'):\n",
    "    print('Old version is already available create a new version.')\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)\n",
    "\n",
    "# Define subfolders and ensure they exist:\n",
    "models_dir = os.path.join(file_path, 'models')\n",
    "reports_dir = os.path.join(file_path, 'reports')\n",
    "\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(reports_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefadff6",
   "metadata": {},
   "source": [
    "### Get Artifact Paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ed8efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artifact_paths(models_dir: str, reports_dir: str, tag: str) -> dict:\n",
    "    \"\"\"\n",
    "    Return file paths (no new dirs) for this run's artifacts, using the tag in filenames.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"model_path\":   Path(models_dir)  / f\"{tag}.keras\",\n",
    "        \"history_pkl\":  Path(reports_dir) / f\"history_{tag}.pkl\",\n",
    "        \"evaluation_pkl\": Path(reports_dir) / f\"eval_{tag}.pkl\",\n",
    "        \"curve_png\":    Path(reports_dir) / f\"curves_{tag}.png\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f886fe24",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb61aea",
   "metadata": {},
   "source": [
    "## Load  Top 5 Scenarios from Batch 16 Run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8dfd7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_version = \"step_1\"  # adjust to your step_1 folder name\n",
    "df_prev = pd.read_csv(f\"outputs/{prev_version}/reports/grid_report_bs16.csv\")\n",
    "\n",
    "# same ranking rule as before\n",
    "df_prev = df_prev.sort_values(by=[\"val_accuracy\", \"val_loss\"], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "TOP_N = 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d08a42",
   "metadata": {},
   "source": [
    "## Set Scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eead31e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [{'dropout': 0.3, 'kernel_size': 5, 'activation': 'relu', 'optimizer': 'adamax'}, {'dropout': 0.3, 'kernel_size': 3, 'activation': 'elu', 'optimizer': 'adamax'}]\n"
     ]
    }
   ],
   "source": [
    "SCENARIOS = df_prev.head(TOP_N)[[\"dropout\",\"kernel_size\",\"activation\",\"optimizer\"]].to_dict(orient=\"records\")\n",
    "print(len(SCENARIOS), SCENARIOS[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0360e99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d28d9a",
   "metadata": {},
   "source": [
    "## Set Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7b9abbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for the images are ['powdery_mildew', 'healthy']\n"
     ]
    }
   ],
   "source": [
    "# Set the labels\n",
    "labels = os.listdir(train_dir)\n",
    "print('Label for the images are', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6931e95",
   "metadata": {},
   "source": [
    "## Set image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8be5db40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import saved image shape embedding\n",
    "import joblib\n",
    "image_shape = joblib.load(filename=f\"outputs/v1/image_shape.pkl\") # Set from previous run\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ddfb0c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be1e8e5",
   "metadata": {},
   "source": [
    "# Image Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a252e7bf",
   "metadata": {},
   "source": [
    "### Image Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5eca2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b4ca11",
   "metadata": {},
   "source": [
    "### Initialize ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5779632",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
    "                                          width_shift_range=0.10,\n",
    "                                          height_shift_range=0.10,\n",
    "                                          shear_range=0.1,\n",
    "                                          zoom_range=0.1,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          fill_mode='nearest',\n",
    "                                          rescale=1./255\n",
    "                                          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de41e30",
   "metadata": {},
   "source": [
    "### Augment image datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a4cf019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2944 images belonging to 2 classes.\n",
      "Found 420 images belonging to 2 classes.\n",
      "Found 844 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'healthy': 0, 'powdery_mildew': 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Set:\n",
    "train_set = augmented_image_data.flow_from_directory(train_dir,\n",
    "                                                     target_size=image_shape[:2],\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     class_mode='binary',\n",
    "                                                     shuffle=True\n",
    "                                                     )\n",
    "\n",
    "# Validation Set:\n",
    "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_dir,\n",
    "                                                                        target_size=image_shape[:2],\n",
    "                                                                        color_mode='rgb',\n",
    "                                                                        batch_size=batch_size,\n",
    "                                                                        class_mode='binary',\n",
    "                                                                        shuffle=False\n",
    "                                                                        )\n",
    "\n",
    "# Test Set:\n",
    "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_dir,\n",
    "                                                                  target_size=image_shape[:2],\n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='binary',\n",
    "                                                                  shuffle=False\n",
    "                                                                  )\n",
    "\n",
    "\n",
    "train_set.class_indices\n",
    "validation_set.class_indices\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940625c9",
   "metadata": {},
   "source": [
    "### Save class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b91ff75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/step_2/class_indices.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(value=train_set.class_indices,\n",
    "            filename=f\"{file_path}/class_indices.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8772adb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891de0de",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ebbb44",
   "metadata": {},
   "source": [
    "## ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588f923",
   "metadata": {},
   "source": [
    "### Model Builder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59352bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(cfg):\n",
    "    \"\"\"\n",
    "    CNN builder using the scenario dict `cfg`.\n",
    "    Expects keys: 'kernel_size', 'dropout', 'activation'.\n",
    "    Uses global `image_shape`.\n",
    "    \"\"\"\n",
    "    k   = int(cfg[\"kernel_size\"])\n",
    "    do  = float(cfg[\"dropout\"])\n",
    "    act = str(cfg[\"activation\"])\n",
    "\n",
    "    m = Sequential(name=f\"cnn_k{k}_do{do}_{act}\")\n",
    "    m.add(Conv2D(32, (k, k), padding='same', activation=act, input_shape=image_shape))\n",
    "    m.add(BatchNormalization()); m.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    m.add(Conv2D(64, (k, k), padding='same', activation=act))\n",
    "    m.add(BatchNormalization()); m.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    m.add(Conv2D(64, (k, k), padding='same', activation=act))\n",
    "    m.add(BatchNormalization()); m.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    m.add(Flatten())\n",
    "    m.add(Dropout(do))\n",
    "    m.add(Dense(64, activation=act))\n",
    "    m.add(Dropout(do))\n",
    "    m.add(Dense(1, activation='sigmoid'))\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f5e77",
   "metadata": {},
   "source": [
    "### Save History Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5739d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history_plot(history, out_png):\n",
    "    h = history.history\n",
    "    plt.figure(figsize=(8,5))\n",
    "    if \"accuracy\" in h and \"val_accuracy\" in h:\n",
    "        plt.plot(h[\"accuracy\"], label=\"train_acc\")\n",
    "        plt.plot(h[\"val_accuracy\"], label=\"val_acc\")\n",
    "    if \"loss\" in h and \"val_loss\" in h:\n",
    "        plt.plot(h[\"loss\"], label=\"train_loss\")\n",
    "        plt.plot(h[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Value\"); plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=120); plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1e1875",
   "metadata": {},
   "source": [
    "### Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72106854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(cfg: dict):\n",
    "    # tag + artifact paths\n",
    "    tag = run_tag(cfg, version, batch_size, seed=SEED)\n",
    "    P = get_artifact_paths(models_dir, reports_dir, tag)\n",
    "\n",
    "    # build & compile model\n",
    "    model = build_model(cfg)\n",
    "    model.compile(\n",
    "        optimizer=cfg[\"optimizer\"],\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[tf.keras.metrics.BinaryAccuracy(name=\"accuracy\")]\n",
    "    )\n",
    "\n",
    "    # callbacks (save best by val_accuracy)\n",
    "    cbs = [\n",
    "        # Stop training if val_accuracy doesn't improve for 4 epochs, roll back to best weights:\n",
    "        EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=4, restore_best_weights=True, verbose=1),\n",
    "        # Keep the best model:\n",
    "        ModelCheckpoint(filepath=str(P[\"model_path\"]), monitor=\"val_accuracy\", mode=\"max\", save_best_only=True, verbose=1),\n",
    "    ]\n",
    "\n",
    "    # Fit Model\n",
    "    history = model.fit(\n",
    "        train_set,\n",
    "        epochs= epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=validation_set,\n",
    "        callbacks=cbs,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Save history + curves\n",
    "    joblib.dump(history.history, P[\"history_pkl\"])\n",
    "    save_history_plot(history, P[\"curve_png\"])\n",
    "\n",
    "    # Evaluate on validation: get probabilities, true labels, and hard preds\n",
    "    validation_set.reset()                                      # start from first batch, keep order aligned\n",
    "    y_prob = model.predict(validation_set, verbose=0).squeeze()  # (N,)\n",
    "    y_true = validation_set.classes                              # (N,)\n",
    "    y_pred = (y_prob >= 0.5).astype(int)                         # threshold @ 0.5\n",
    "\n",
    "    # Capture val_loss and Keras accuracy for the same validation set ---\n",
    "    validation_set.reset()                                       # reset again before evaluate\n",
    "    val_loss, val_acc = model.evaluate(validation_set, verbose=0) # loss & accuracy from the compiled metrics\n",
    "\n",
    "    # Compute metrics\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    cm   = confusion_matrix(y_true, y_pred).tolist()\n",
    "\n",
    "    # --- Summary, CSV-ready ---\n",
    "    out = {\n",
    "        \"tag\": tag,                          # Unique ID\n",
    "        \"version\": version,\n",
    "        \"batch_size\": batch_size,\n",
    "        **cfg,                               # includes dropout, kernel_size, activation, optimizer\n",
    "        \"epochs_trained\": len(history.history[\"loss\"]),\n",
    "        \"val_loss\": float(val_loss),\n",
    "        \"val_accuracy\": float(val_acc),\n",
    "        \"val_precision\": float(prec),\n",
    "        \"val_recall\": float(rec),\n",
    "        \"val_f1\": float(f1),\n",
    "        \"confusion_matrix\": cm,\n",
    "    }\n",
    "\n",
    "    # Save Evaluation Pickle\n",
    "    joblib.dump(out, P[\"evaluation_pkl\"])\n",
    "\n",
    "    # Hand back the summary so the caller can append to a list/DataFrame\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be4aa28",
   "metadata": {},
   "source": [
    "### Execute Scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c95fc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [1/5] {'dropout': 0.3, 'kernel_size': 5, 'activation': 'relu', 'optimizer': 'adamax'} ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcelldemeter/GIT/CodeInstitute/ci-p5-mildew-detector/mildew-env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-10-12 03:41:48.339703: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2025-10-12 03:41:48.339741: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2025-10-12 03:41:48.339750: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.66 GB\n",
      "2025-10-12 03:41:48.339768: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-10-12 03:41:48.339781: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/marcelldemeter/GIT/CodeInstitute/ci-p5-mildew-detector/mildew-env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 03:41:49.296934: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from None to 0.50000, saving model to outputs/step_2/models/step_2_bs32_k5_do0.3_act-relu_opt-adamax_seed27.keras\n",
      "92/92 - 25s - 271ms/step - accuracy: 0.9667 - loss: 0.9076 - val_accuracy: 0.5000 - val_loss: 31.0168\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.50000\n",
      "92/92 - 22s - 235ms/step - accuracy: 0.9891 - loss: 0.2457 - val_accuracy: 0.5000 - val_loss: 50.6415\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.50000\n",
      "92/92 - 21s - 232ms/step - accuracy: 0.9874 - loss: 0.2806 - val_accuracy: 0.5000 - val_loss: 47.4519\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.50000\n",
      "92/92 - 21s - 232ms/step - accuracy: 0.9932 - loss: 0.1790 - val_accuracy: 0.5000 - val_loss: 53.2405\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.50000 to 0.89762, saving model to outputs/step_2/models/step_2_bs32_k5_do0.3_act-relu_opt-adamax_seed27.keras\n",
      "92/92 - 21s - 233ms/step - accuracy: 0.9895 - loss: 0.3636 - val_accuracy: 0.8976 - val_loss: 1.4242\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.89762 to 0.98810, saving model to outputs/step_2/models/step_2_bs32_k5_do0.3_act-relu_opt-adamax_seed27.keras\n",
      "92/92 - 21s - 233ms/step - accuracy: 0.9874 - loss: 0.4177 - val_accuracy: 0.9881 - val_loss: 0.2917\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.98810 to 0.99762, saving model to outputs/step_2/models/step_2_bs32_k5_do0.3_act-relu_opt-adamax_seed27.keras\n",
      "92/92 - 21s - 233ms/step - accuracy: 0.9891 - loss: 0.2841 - val_accuracy: 0.9976 - val_loss: 0.2428\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.99762\n",
      "92/92 - 21s - 233ms/step - accuracy: 0.9922 - loss: 0.1827 - val_accuracy: 0.9952 - val_loss: 0.2892\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.99762\n",
      "92/92 - 22s - 234ms/step - accuracy: 0.9912 - loss: 0.2652 - val_accuracy: 0.9952 - val_loss: 0.0712\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.99762\n",
      "92/92 - 21s - 232ms/step - accuracy: 0.9939 - loss: 0.1837 - val_accuracy: 0.7500 - val_loss: 11.5099\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.99762\n",
      "92/92 - 21s - 232ms/step - accuracy: 0.9935 - loss: 0.2059 - val_accuracy: 0.6238 - val_loss: 9.6588\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\n",
      "=== [2/5] {'dropout': 0.3, 'kernel_size': 3, 'activation': 'elu', 'optimizer': 'adamax'} ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcelldemeter/GIT/CodeInstitute/ci-p5-mildew-detector/mildew-env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\n",
      "Epoch 1: val_accuracy improved from None to 0.70238, saving model to outputs/step_2/models/step_2_bs32_k3_do0.3_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 30s - 331ms/step - accuracy: 0.9575 - loss: 0.6087 - val_accuracy: 0.7024 - val_loss: 3.9012\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.70238\n",
      "92/92 - 30s - 322ms/step - accuracy: 0.9847 - loss: 0.0930 - val_accuracy: 0.5190 - val_loss: 14.6210\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.70238\n",
      "92/92 - 29s - 317ms/step - accuracy: 0.9878 - loss: 0.0359 - val_accuracy: 0.5976 - val_loss: 7.4959\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.70238 to 0.80238, saving model to outputs/step_2/models/step_2_bs32_k3_do0.3_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 34s - 373ms/step - accuracy: 0.9932 - loss: 0.0201 - val_accuracy: 0.8024 - val_loss: 1.7244\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.80238 to 0.98810, saving model to outputs/step_2/models/step_2_bs32_k3_do0.3_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 34s - 374ms/step - accuracy: 0.9963 - loss: 0.0122 - val_accuracy: 0.9881 - val_loss: 0.0391\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.98810 to 0.99762, saving model to outputs/step_2/models/step_2_bs32_k3_do0.3_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 35s - 377ms/step - accuracy: 0.9942 - loss: 0.0191 - val_accuracy: 0.9976 - val_loss: 0.0081\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.99762\n",
      "92/92 - 28s - 300ms/step - accuracy: 0.9952 - loss: 0.0161 - val_accuracy: 0.9952 - val_loss: 0.0047\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.99762 to 1.00000, saving model to outputs/step_2/models/step_2_bs32_k3_do0.3_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 34s - 366ms/step - accuracy: 0.9932 - loss: 0.0175 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "92/92 - 27s - 296ms/step - accuracy: 0.9963 - loss: 0.0069 - val_accuracy: 0.9976 - val_loss: 0.0039\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "92/92 - 34s - 368ms/step - accuracy: 0.9966 - loss: 0.0120 - val_accuracy: 0.9976 - val_loss: 0.0037\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "92/92 - 33s - 364ms/step - accuracy: 0.9959 - loss: 0.0128 - val_accuracy: 0.9976 - val_loss: 0.0076\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "92/92 - 33s - 359ms/step - accuracy: 0.9966 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 4.3614e-04\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\n",
      "=== [3/5] {'dropout': 0.5, 'kernel_size': 5, 'activation': 'elu', 'optimizer': 'adamax'} ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcelldemeter/GIT/CodeInstitute/ci-p5-mildew-detector/mildew-env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\n",
      "Epoch 1: val_accuracy improved from None to 0.50000, saving model to outputs/step_2/models/step_2_bs32_k5_do0.5_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 36s - 393ms/step - accuracy: 0.9592 - loss: 0.3779 - val_accuracy: 0.5000 - val_loss: 28.6869\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.50000\n",
      "92/92 - 33s - 359ms/step - accuracy: 0.9738 - loss: 0.0836 - val_accuracy: 0.5000 - val_loss: 45.7233\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.50000\n",
      "92/92 - 38s - 418ms/step - accuracy: 0.9817 - loss: 0.0675 - val_accuracy: 0.5000 - val_loss: 23.2244\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.50000\n",
      "92/92 - 38s - 417ms/step - accuracy: 0.9840 - loss: 0.0602 - val_accuracy: 0.5000 - val_loss: 22.6320\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.50000 to 0.94286, saving model to outputs/step_2/models/step_2_bs32_k5_do0.5_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 40s - 435ms/step - accuracy: 0.9864 - loss: 0.0285 - val_accuracy: 0.9429 - val_loss: 0.2012\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.94286\n",
      "92/92 - 32s - 350ms/step - accuracy: 0.9922 - loss: 0.0210 - val_accuracy: 0.5452 - val_loss: 9.1287\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.94286 to 0.99524, saving model to outputs/step_2/models/step_2_bs32_k5_do0.5_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 37s - 408ms/step - accuracy: 0.9891 - loss: 0.0538 - val_accuracy: 0.9952 - val_loss: 0.0260\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.99524 to 0.99762, saving model to outputs/step_2/models/step_2_bs32_k5_do0.5_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 33s - 355ms/step - accuracy: 0.9895 - loss: 0.0386 - val_accuracy: 0.9976 - val_loss: 0.0099\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.99762\n",
      "92/92 - 33s - 359ms/step - accuracy: 0.9929 - loss: 0.0200 - val_accuracy: 0.9976 - val_loss: 0.0067\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.99762\n",
      "92/92 - 37s - 400ms/step - accuracy: 0.9983 - loss: 0.0064 - val_accuracy: 0.9976 - val_loss: 0.0039\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.99762\n",
      "92/92 - 37s - 402ms/step - accuracy: 0.9942 - loss: 0.0166 - val_accuracy: 0.9881 - val_loss: 0.0589\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 12: val_accuracy improved from 0.99762 to 1.00000, saving model to outputs/step_2/models/step_2_bs32_k5_do0.5_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 37s - 404ms/step - accuracy: 0.9922 - loss: 0.0295 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "92/92 - 33s - 355ms/step - accuracy: 0.9952 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "92/92 - 37s - 404ms/step - accuracy: 0.9966 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "92/92 - 37s - 399ms/step - accuracy: 0.9966 - loss: 0.0165 - val_accuracy: 0.8310 - val_loss: 2.4455\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "92/92 - 38s - 416ms/step - accuracy: 0.9932 - loss: 0.0309 - val_accuracy: 0.9976 - val_loss: 0.0061\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\n",
      "=== [4/5] {'dropout': 0.3, 'kernel_size': 5, 'activation': 'elu', 'optimizer': 'adamax'} ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcelldemeter/GIT/CodeInstitute/ci-p5-mildew-detector/mildew-env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\n",
      "Epoch 1: val_accuracy improved from None to 0.50000, saving model to outputs/step_2/models/step_2_bs32_k5_do0.3_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 34s - 369ms/step - accuracy: 0.9606 - loss: 0.4107 - val_accuracy: 0.5000 - val_loss: 37.0386\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.50000\n",
      "92/92 - 31s - 333ms/step - accuracy: 0.9878 - loss: 0.0438 - val_accuracy: 0.5000 - val_loss: 47.6419\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.50000 to 0.51429, saving model to outputs/step_2/models/step_2_bs32_k5_do0.3_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 35s - 382ms/step - accuracy: 0.9885 - loss: 0.0428 - val_accuracy: 0.5143 - val_loss: 24.7974\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.51429 to 0.52857, saving model to outputs/step_2/models/step_2_bs32_k5_do0.3_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 38s - 408ms/step - accuracy: 0.9932 - loss: 0.0300 - val_accuracy: 0.5286 - val_loss: 14.5665\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.52857 to 0.85476, saving model to outputs/step_2/models/step_2_bs32_k5_do0.3_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 32s - 353ms/step - accuracy: 0.9874 - loss: 0.0484 - val_accuracy: 0.8548 - val_loss: 1.1504\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.85476 to 0.92857, saving model to outputs/step_2/models/step_2_bs32_k5_do0.3_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 33s - 354ms/step - accuracy: 0.9925 - loss: 0.0260 - val_accuracy: 0.9286 - val_loss: 0.4164\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.92857 to 0.99524, saving model to outputs/step_2/models/step_2_bs32_k5_do0.3_act-elu_opt-adamax_seed27.keras\n",
      "92/92 - 32s - 352ms/step - accuracy: 0.9946 - loss: 0.0200 - val_accuracy: 0.9952 - val_loss: 0.0150\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.99524\n",
      "92/92 - 32s - 346ms/step - accuracy: 0.9878 - loss: 0.0424 - val_accuracy: 0.7786 - val_loss: 1.2132\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.99524\n",
      "92/92 - 32s - 347ms/step - accuracy: 0.9925 - loss: 0.0243 - val_accuracy: 0.9929 - val_loss: 0.0250\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.99524\n",
      "92/92 - 36s - 392ms/step - accuracy: 0.9929 - loss: 0.0222 - val_accuracy: 0.9929 - val_loss: 0.0181\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.99524\n",
      "92/92 - 36s - 394ms/step - accuracy: 0.9956 - loss: 0.0120 - val_accuracy: 0.9810 - val_loss: 0.0458\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\n",
      "=== [5/5] {'dropout': 0.3, 'kernel_size': 3, 'activation': 'relu', 'optimizer': 'adamax'} ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcelldemeter/GIT/CodeInstitute/ci-p5-mildew-detector/mildew-env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\n",
      "Epoch 1: val_accuracy improved from None to 0.50000, saving model to outputs/step_2/models/step_2_bs32_k3_do0.3_act-relu_opt-adamax_seed27.keras\n",
      "92/92 - 18s - 201ms/step - accuracy: 0.9711 - loss: 2.3476 - val_accuracy: 0.5000 - val_loss: 60.8139\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.50000\n",
      "92/92 - 17s - 183ms/step - accuracy: 0.9885 - loss: 0.8165 - val_accuracy: 0.5000 - val_loss: 70.1090\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.50000\n",
      "92/92 - 17s - 184ms/step - accuracy: 0.9925 - loss: 0.3912 - val_accuracy: 0.5000 - val_loss: 60.3915\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.50000\n",
      "92/92 - 17s - 183ms/step - accuracy: 0.9922 - loss: 0.4023 - val_accuracy: 0.5000 - val_loss: 51.9764\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.50000 to 0.78810, saving model to outputs/step_2/models/step_2_bs32_k3_do0.3_act-relu_opt-adamax_seed27.keras\n",
      "92/92 - 17s - 183ms/step - accuracy: 0.9935 - loss: 0.2796 - val_accuracy: 0.7881 - val_loss: 6.4545\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.78810\n",
      "92/92 - 17s - 183ms/step - accuracy: 0.9922 - loss: 0.5688 - val_accuracy: 0.7333 - val_loss: 10.1848\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.78810 to 0.97619, saving model to outputs/step_2/models/step_2_bs32_k3_do0.3_act-relu_opt-adamax_seed27.keras\n",
      "92/92 - 17s - 183ms/step - accuracy: 0.9901 - loss: 0.4782 - val_accuracy: 0.9762 - val_loss: 2.0888\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.97619\n",
      "92/92 - 17s - 183ms/step - accuracy: 0.9891 - loss: 0.8657 - val_accuracy: 0.9452 - val_loss: 1.8651\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.97619 to 0.98095, saving model to outputs/step_2/models/step_2_bs32_k3_do0.3_act-relu_opt-adamax_seed27.keras\n",
      "92/92 - 17s - 183ms/step - accuracy: 0.9881 - loss: 1.3394 - val_accuracy: 0.9810 - val_loss: 0.7356\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 10: val_accuracy improved from 0.98095 to 1.00000, saving model to outputs/step_2/models/step_2_bs32_k3_do0.3_act-relu_opt-adamax_seed27.keras\n",
      "92/92 - 17s - 183ms/step - accuracy: 0.9827 - loss: 1.2707 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "92/92 - 17s - 182ms/step - accuracy: 0.9861 - loss: 2.0837 - val_accuracy: 0.9643 - val_loss: 11.4770\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "92/92 - 17s - 183ms/step - accuracy: 0.9854 - loss: 1.6300 - val_accuracy: 0.9810 - val_loss: 1.7076\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "92/92 - 17s - 182ms/step - accuracy: 0.9868 - loss: 2.0206 - val_accuracy: 0.9952 - val_loss: 0.2291\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "92/92 - 17s - 183ms/step - accuracy: 0.9888 - loss: 2.1698 - val_accuracy: 0.9833 - val_loss: 2.3565\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\n",
      "Completed 5 runs in ~30.3 min\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "t0 = time.time()\n",
    "for i, cfg in enumerate(SCENARIOS, 1):\n",
    "    print(f\"\\n=== [{i}/{len(SCENARIOS)}] {cfg} ===\")\n",
    "    res = train_and_eval(cfg)          # uses your build_model + callbacks + eval\n",
    "    results.append(res)\n",
    "\n",
    "print(f\"\\nCompleted {len(SCENARIOS)} runs in ~{(time.time()-t0)/60:.1f} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d28f2d7",
   "metadata": {},
   "source": [
    "### Create Dataframe on results and save to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80d80a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved report to: outputs/step_2/reports/grid_report_bs32.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(results).sort_values(\n",
    "    by=[\"val_accuracy\", \"val_loss\"], ascending=[False, True] # Sort by highest accuracy, then lowest loss\n",
    ").reset_index(drop=True)\n",
    "\n",
    "report_csv = os.path.join(reports_dir, f\"grid_report_bs{batch_size}.csv\")\n",
    "df.to_csv(report_csv, index=False)\n",
    "print(f\"Saved report to: {report_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c204f",
   "metadata": {},
   "source": [
    "### See Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b822737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>version</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>epochs_trained</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>step_2_bs32_k3_do0.3_act-relu_opt-adamax_seed27</td>\n",
       "      <td>step_2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>adamax</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[210, 0], [0, 210]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>step_2_bs32_k3_do0.3_act-elu_opt-adamax_seed27</td>\n",
       "      <td>step_2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>adamax</td>\n",
       "      <td>12</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[210, 0], [0, 210]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>step_2_bs32_k5_do0.5_act-elu_opt-adamax_seed27</td>\n",
       "      <td>step_2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>adamax</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[210, 0], [0, 210]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>step_2_bs32_k5_do0.3_act-relu_opt-adamax_seed27</td>\n",
       "      <td>step_2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>adamax</td>\n",
       "      <td>11</td>\n",
       "      <td>0.242814</td>\n",
       "      <td>0.997619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.997613</td>\n",
       "      <td>[[210, 0], [1, 209]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>step_2_bs32_k5_do0.3_act-elu_opt-adamax_seed27</td>\n",
       "      <td>step_2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>adamax</td>\n",
       "      <td>11</td>\n",
       "      <td>0.015024</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.995215</td>\n",
       "      <td>[[210, 0], [2, 208]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tag version  batch_size  \\\n",
       "0  step_2_bs32_k3_do0.3_act-relu_opt-adamax_seed27  step_2          32   \n",
       "1   step_2_bs32_k3_do0.3_act-elu_opt-adamax_seed27  step_2          32   \n",
       "2   step_2_bs32_k5_do0.5_act-elu_opt-adamax_seed27  step_2          32   \n",
       "3  step_2_bs32_k5_do0.3_act-relu_opt-adamax_seed27  step_2          32   \n",
       "4   step_2_bs32_k5_do0.3_act-elu_opt-adamax_seed27  step_2          32   \n",
       "\n",
       "   dropout  kernel_size activation optimizer  epochs_trained  val_loss  \\\n",
       "0      0.3            3       relu    adamax              14  0.000000   \n",
       "1      0.3            3        elu    adamax              12  0.001563   \n",
       "2      0.5            5        elu    adamax              16  0.002002   \n",
       "3      0.3            5       relu    adamax              11  0.242814   \n",
       "4      0.3            5        elu    adamax              11  0.015024   \n",
       "\n",
       "   val_accuracy  val_precision  val_recall    val_f1      confusion_matrix  \n",
       "0      1.000000            1.0    1.000000  1.000000  [[210, 0], [0, 210]]  \n",
       "1      1.000000            1.0    1.000000  1.000000  [[210, 0], [0, 210]]  \n",
       "2      1.000000            1.0    1.000000  1.000000  [[210, 0], [0, 210]]  \n",
       "3      0.997619            1.0    0.995238  0.997613  [[210, 0], [1, 209]]  \n",
       "4      0.995238            1.0    0.990476  0.995215  [[210, 0], [2, 208]]  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5) # Display top 5 results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mildew-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
